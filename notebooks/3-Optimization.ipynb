{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f247fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec39c865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diegof/miniconda3/envs/transfer_learning/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "class Optuna:\n",
    "    def __init__(self, X, y, n_trials=100, model: str = 'RandomForest'):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_trials = n_trials\n",
    "        self.study = optuna.create_study(direction='maximize')\n",
    "        self.model = model\n",
    "\n",
    "    def objective(self, trial):\n",
    "        params = {\n",
    "            'C': trial.suggest_loguniform('C', 1e-10, 1e10),\n",
    "            'kernel': trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "            'degree': trial.suggest_int('degree', 1, 5),\n",
    "            'gamma': trial.suggest_categorical('gamma', ['scale', 'auto']),\n",
    "            'coef0': trial.suggest_uniform('coef0', 0, 10),\n",
    "            'shrinking': trial.suggest_categorical('shrinking', [True, False]),\n",
    "            'probability': trial.suggest_categorical('probability', [True, False]),\n",
    "            'tol': trial.suggest_loguniform('tol', 1e-5, 1e-1),\n",
    "            'decision_function_shape': trial.suggest_categorical('decision_function_shape', ['ovo', 'ovr'])\n",
    "        }\n",
    "        if self.model == 'RandomForest':\n",
    "            self.clf = RandomForestClassifier(**params)\n",
    "        if self.model == 'SVC':\n",
    "            self.clf = SVC(**params)\n",
    "        return cross_val_score(self.clf, self.X, self.y, cv=5).mean()\n",
    "\n",
    "    def optimize(self):\n",
    "        self.study.optimize(self.objective, n_trials=self.n_trials)\n",
    "        return self.study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a462a18",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['p_0', 'p_1', 'p_2', 'p_3', 'p_4', 'p_5', 'p_6', 'p_7', 'p_8', 'p_9',\n",
       "       ...\n",
       "       'p_2003', 'p_2004', 'p_2005', 'p_2006', 'p_2007', 'p_2008', 'p_2009',\n",
       "       'p_2010', 'p_2011', 'response'],\n",
       "      dtype='object', length=2013)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/encoded/physicochemical_WOLS870103.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f4c104b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "X = df.drop('response', axis=1).values\n",
    "y = df['response'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9fa734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-04 17:42:00,888] A new study created in memory with name: no-name-cc41220c-dcc9-46ab-86f3-831377b75723\n",
      "/tmp/ipykernel_293446/2829584330.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-10, 1e10),\n",
      "/tmp/ipykernel_293446/2829584330.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'coef0': trial.suggest_uniform('coef0', 0, 10),\n",
      "/tmp/ipykernel_293446/2829584330.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'tol': trial.suggest_loguniform('tol', 1e-5, 1e-1),\n",
      "[I 2024-12-04 17:51:19,431] Trial 0 finished with value: 0.630708114046701 and parameters: {'C': 4785889.9780677445, 'kernel': 'rbf', 'degree': 5, 'gamma': 'scale', 'coef0': 7.429097448132248, 'shrinking': False, 'probability': True, 'tol': 0.0043663652111854325, 'decision_function_shape': 'ovr'}. Best is trial 0 with value: 0.630708114046701.\n",
      "/tmp/ipykernel_293446/2829584330.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-10, 1e10),\n",
      "/tmp/ipykernel_293446/2829584330.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'coef0': trial.suggest_uniform('coef0', 0, 10),\n",
      "/tmp/ipykernel_293446/2829584330.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'tol': trial.suggest_loguniform('tol', 1e-5, 1e-1),\n",
      "[I 2024-12-04 17:53:12,179] Trial 1 finished with value: 0.6203306342269552 and parameters: {'C': 233280.68389436475, 'kernel': 'linear', 'degree': 2, 'gamma': 'auto', 'coef0': 8.09629002237622, 'shrinking': True, 'probability': False, 'tol': 0.015134780077440669, 'decision_function_shape': 'ovo'}. Best is trial 0 with value: 0.630708114046701.\n",
      "/tmp/ipykernel_293446/2829584330.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-10, 1e10),\n",
      "/tmp/ipykernel_293446/2829584330.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'coef0': trial.suggest_uniform('coef0', 0, 10),\n",
      "/tmp/ipykernel_293446/2829584330.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'tol': trial.suggest_loguniform('tol', 1e-5, 1e-1),\n",
      "[I 2024-12-04 18:15:17,124] Trial 2 finished with value: 0.5586252461852321 and parameters: {'C': 1.470813907739253e-05, 'kernel': 'sigmoid', 'degree': 2, 'gamma': 'scale', 'coef0': 0.5096568624440823, 'shrinking': True, 'probability': True, 'tol': 0.023522170105555646, 'decision_function_shape': 'ovr'}. Best is trial 0 with value: 0.630708114046701.\n",
      "/tmp/ipykernel_293446/2829584330.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-10, 1e10),\n",
      "/tmp/ipykernel_293446/2829584330.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'coef0': trial.suggest_uniform('coef0', 0, 10),\n",
      "/tmp/ipykernel_293446/2829584330.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'tol': trial.suggest_loguniform('tol', 1e-5, 1e-1),\n",
      "[I 2024-12-04 18:36:32,275] Trial 3 finished with value: 0.5302205769245318 and parameters: {'C': 4.595560916904582e-05, 'kernel': 'poly', 'degree': 1, 'gamma': 'auto', 'coef0': 3.1460209323409027, 'shrinking': True, 'probability': True, 'tol': 0.05995525860204814, 'decision_function_shape': 'ovr'}. Best is trial 0 with value: 0.630708114046701.\n",
      "/tmp/ipykernel_293446/2829584330.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-10, 1e10),\n",
      "/tmp/ipykernel_293446/2829584330.py:17: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'coef0': trial.suggest_uniform('coef0', 0, 10),\n",
      "/tmp/ipykernel_293446/2829584330.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'tol': trial.suggest_loguniform('tol', 1e-5, 1e-1),\n",
      "[I 2024-12-04 18:41:43,471] Trial 4 finished with value: 0.5546044939154526 and parameters: {'C': 0.0002725437831609516, 'kernel': 'sigmoid', 'degree': 4, 'gamma': 'auto', 'coef0': 1.5726779365513854, 'shrinking': False, 'probability': False, 'tol': 0.006741332568430648, 'decision_function_shape': 'ovr'}. Best is trial 0 with value: 0.630708114046701.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 4785889.9780677445,\n",
       " 'kernel': 'rbf',\n",
       " 'degree': 5,\n",
       " 'gamma': 'scale',\n",
       " 'coef0': 7.429097448132248,\n",
       " 'shrinking': False,\n",
       " 'probability': True,\n",
       " 'tol': 0.0043663652111854325,\n",
       " 'decision_function_shape': 'ovr'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = Optuna(X, y, n_trials=5, model='SVC')\n",
    "opt.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddf08d9",
   "metadata": {},
   "source": [
    "## HalvingSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb90e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, HalvingGridSearchCV, HalvingRandomSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve, auc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e60df3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Models():\n",
    "    def __init__(self, linspace_size: int = 3, n_iter_search: int = 15):\n",
    "        self.linspace_size = 3\n",
    "        self.algorithms = {\n",
    "                \"knn\": ( \n",
    "                    KNeighborsClassifier(),\n",
    "                    {\n",
    "                        \"n_neighbors\": np.linspace(3, 10, num=linspace_size, dtype=int),\n",
    "                        \"weights\": [\"uniform\", \"distance\"],\n",
    "                        \"p\": np.linspace(1, 10, num=3, dtype=int),\n",
    "                        \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "                        \"leaf_size\": np.linspace(10, 100, num=linspace_size, dtype=int),\n",
    "                        \"metric\": ['euclidean', 'manhattan', 'chebyshev', 'minkowski']\n",
    "                    }\n",
    "                ),\n",
    "                \"dt\": (\n",
    "                    DecisionTreeClassifier(),\n",
    "                    {\n",
    "                        \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "                        \"splitter\": [\"best\", \"random\"],\n",
    "                        \"max_depth\": np.linspace(1, 100, num=linspace_size, dtype=int),\n",
    "                        \"min_samples_split\": np.linspace(2, 100, num=linspace_size, dtype=int),\n",
    "                        \"min_samples_leaf\": np.linspace(1, 100, num=linspace_size, dtype=int),\n",
    "                        \"max_features\": [\"sqrt\", \"log2\"],\n",
    "                        \"ccp_alpha\": np.linspace(0, 0.1, num=3),\n",
    "                    }\n",
    "                ),\n",
    "                \"svm\": (\n",
    "                    SVC(),\n",
    "                    {\n",
    "                        \"C\": np.linspace(0.1, 10, num=linspace_size),\n",
    "                        \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "                        \"degree\": np.linspace(1, 10, num=linspace_size, dtype=int),\n",
    "                        \"gamma\": [\"scale\", \"auto\"],\n",
    "                        \"coef0\": np.linspace(0, 10, num=linspace_size),\n",
    "                        \"shrinking\": [True, False],\n",
    "                        \"probability\": [True, False],\n",
    "                        \"tol\": np.linspace(0.0001, 0.01, num=linspace_size),\n",
    "                    }\n",
    "                ),\n",
    "                \"rf\": (\n",
    "                    RandomForestClassifier(),\n",
    "                    {\n",
    "                        \"n_estimators\": np.linspace(100, 200, num=linspace_size, dtype=int), # 30 segundos\n",
    "                        \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "                        \"max_depth\": np.linspace(1, 100, num=linspace_size, dtype=int),\n",
    "                        #\"min_samples_split\": np.linspace(2, 10, num=linspace_size, dtype=int), 20 segundos\n",
    "                        #\"min_samples_leaf\": np.linspace(1, 10, num=linspace_size, dtype=int),\n",
    "                        #\"max_leaf_nodes\": np.linspace(10, 90, num=9, dtype=int), # 1 minuto y algo, Afecta demasiado al tiempo\n",
    "                        #\"min_impurity_decrease\": np.linspace(0, 0.1, num=linspace_size),\n",
    "                        \"max_features\": [\"sqrt\", \"log2\"],\n",
    "                        \"ccp_alpha\": np.linspace(0, 0.1, num=linspace_size),\n",
    "                        \"class_weight\": [\"balanced\", \"balanced_subsample\"]\n",
    "                    }\n",
    "                ),\n",
    "                \"ada\": (\n",
    "                    AdaBoostClassifier(),\n",
    "                    {\n",
    "                        \"n_estimators\": np.linspace(10, 100, num=linspace_size, dtype=int),\n",
    "                        \"learning_rate\": np.linspace(0.1, 1, num=linspace_size),\n",
    "                        \"algorithm\": [\"SAMME\", \"SAMME.R\"],\n",
    "                    }\n",
    "                )    \n",
    "        }\n",
    "        self.n_iter_search = n_iter_search\n",
    "\n",
    "    def report(self, results, n_top: int = 3):\n",
    "        export_list = []\n",
    "        for i in range(1, n_top + 1):\n",
    "            candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n",
    "            for candidate in candidates:\n",
    "                export_list.append({\n",
    "                    \"rank\": i,\n",
    "                    \"mean_test_score\": results[\"mean_test_score\"][candidate],\n",
    "                    \"std_test_score\": results[\"std_test_score\"][candidate],\n",
    "                    \"params\": results[\"params\"][candidate]\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(export_list, columns=[\"rank\", \"mean_test_score\", \"std_test_score\", \"params\"])\n",
    "\n",
    "    def random_search(self, algorithm: str, seed: int = 42):\n",
    "        return RandomizedSearchCV(self.algorithms[algorithm][0], self.algorithms[algorithm][1], n_iter=self.n_iter_search, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    def grid_search(self, algorithm: str):\n",
    "        return GridSearchCV(self.algorithms[algorithm][0], self.algorithms[algorithm][1], n_jobs=-1)\n",
    "    \n",
    "    def halving_search(self, algorithm: str):\n",
    "        return HalvingGridSearchCV(self.algorithms[algorithm][0], self.algorithms[algorithm][1], n_jobs=-1)\n",
    "    \n",
    "    def halving_search_f1(self, algorithm: str):\n",
    "        scoring = make_scorer(f1_score, average='macro')\n",
    "        return HalvingGridSearchCV(\n",
    "            estimator=self.algorithms[algorithm][0], \n",
    "            param_grid=self.algorithms[algorithm][1], \n",
    "            n_jobs=-1, \n",
    "            scoring=scoring\n",
    "            )\n",
    "\n",
    "    \n",
    "    def compare_search(self, dataset: str, X: np.array, y: np.array, algorithm: str, seed: int = 42):\n",
    "        export_list = []\n",
    "        \n",
    "        print(f\"Running Grid Search with {dataset} and {algorithm}...\")\n",
    "        grid_search = self.grid_search(algorithm)\n",
    "        \n",
    "        start = time()\n",
    "        grid_search.fit(X, y)\n",
    "        time_spent = time() - start\n",
    "\n",
    "        print(\"Grid Search took %.2f seconds\" % (time_spent))\n",
    "\n",
    "        results = grid_search.cv_results_\n",
    "\n",
    "        candidate = np.flatnonzero(results[\"rank_test_score\"] == 1)[0]\n",
    "        \n",
    "        export_list.append({\n",
    "            \"dataset\": dataset,\n",
    "            \"type\": \"grid\",\n",
    "            \"time\": time_spent,\n",
    "            \"algorithm\": algorithm,\n",
    "            \"mean_test_score\": results[\"mean_test_score\"][candidate],\n",
    "            \"std_test_score\": results[\"std_test_score\"][candidate],\n",
    "            \"params\": results[\"params\"][candidate]\n",
    "        })\n",
    "\n",
    "        print(\"Running Random Search...\")\n",
    "        random_search = self.random_search(algorithm, seed)\n",
    "\n",
    "        start = time()\n",
    "        random_search.fit(X, y)\n",
    "        time_spent = time() - start\n",
    "\n",
    "        print(\"Random Search took %.2f seconds\" % (time_spent))\n",
    "\n",
    "        results = random_search.cv_results_\n",
    "\n",
    "        candidate = np.flatnonzero(results[\"rank_test_score\"] == 1)[0]\n",
    "\n",
    "        export_list.append({\n",
    "            \"dataset\": dataset,\n",
    "            \"type\": \"random\",\n",
    "            \"time\": time_spent,\n",
    "            \"algorithm\": algorithm,\n",
    "            \"mean_test_score\": results[\"mean_test_score\"][candidate],\n",
    "            \"std_test_score\": results[\"std_test_score\"][candidate],\n",
    "            \"params\": results[\"params\"][candidate]\n",
    "        })\n",
    "\n",
    "        print(\"Running Halving Grid Search...\")\n",
    "        halving_search = self.halving_search(algorithm)\n",
    "\n",
    "        start = time()\n",
    "        halving_search.fit(X, y)\n",
    "        time_spent = time() - start\n",
    "\n",
    "        print(\"Halving Grid Search took %.2f seconds\" % (time_spent))\n",
    "\n",
    "        results = halving_search.cv_results_\n",
    "        \n",
    "        candidate = np.flatnonzero(results[\"rank_test_score\"] == 1)[0]\n",
    "\n",
    "        export_list.append({\n",
    "            \"dataset\": dataset,\n",
    "            \"type\": \"halving\",\n",
    "            \"time\": time_spent,\n",
    "            \"algorithm\": algorithm,\n",
    "            \"mean_test_score\": results[\"mean_test_score\"][candidate],\n",
    "            \"std_test_score\": results[\"std_test_score\"][candidate],\n",
    "            \"params\": results[\"params\"][candidate]\n",
    "        })\n",
    "\n",
    "        return pd.DataFrame(export_list, columns=[\"dataset\", \"type\", \"time\", \"algorithm\", \"mean_test_score\", \"std_test_score\", \"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6703941",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('response', axis=1).values\n",
    "y = df['response'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec90f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_instance = Models(linspace_size=10, n_iter_search=50)\n",
    "results = pd.DataFrame(columns=[\"dataset\", \"algorithm\", \"rank\", \"mean_test_score\", \"std_test_score\", \"params\"])\n",
    "seed = 42\n",
    "\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.1, random_state=seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=seed)\n",
    "\n",
    "halving_search = models_instance.halving_search_f1(\"svm\")\n",
    "halving_search.fit(X_train, np.squeeze(y_train))\n",
    "\n",
    "result = models_instance.report(halving_search.cv_results_)\n",
    "result.insert(0, \"best_params\", halving_search.best_params_)\n",
    "result.insert(1, \"best_score\", halving_search.best_score_)\n",
    "\n",
    "results = pd.concat([results, result])\n",
    "\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transfer_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
