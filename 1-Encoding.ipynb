{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fe4347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.fft import fft\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5e7d50",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "class PhysicochemicalEncoder:\n",
    "\n",
    "    def __init__(self,\n",
    "                 dataset=None,\n",
    "                 sep_dataset=\",\",\n",
    "                 property_encoder=\"Group_0\",\n",
    "                 dataset_encoder=None,\n",
    "                 name_column_seq=\"sequence\",\n",
    "                 columns_to_ignore=[]):\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.sep_dataset = sep_dataset\n",
    "\n",
    "        self.property_encoder = property_encoder\n",
    "        self.dataset_encoder = dataset_encoder\n",
    "        self.name_column_seq = name_column_seq\n",
    "        self.columns_to_ignore = columns_to_ignore\n",
    "\n",
    "        self.possible_residues = [\n",
    "            'A',\n",
    "            'C',\n",
    "            'D',\n",
    "            'E',\n",
    "            'F',\n",
    "            'G',\n",
    "            'H',\n",
    "            'I',\n",
    "            'N',\n",
    "            'K',\n",
    "            'L',\n",
    "            'M',\n",
    "            'P',\n",
    "            'Q',\n",
    "            'R',\n",
    "            'S',\n",
    "            'T',\n",
    "            'V',\n",
    "            'W',\n",
    "            'Y'\n",
    "        ]\n",
    "\n",
    "        self.df_data_encoded = None\n",
    "\n",
    "        self.status = False\n",
    "        self.message= \"\"\n",
    "\n",
    "    def run_process(self):\n",
    "        self.__make_validations()\n",
    "\n",
    "        if self.status == True:\n",
    "            self.zero_padding = self.__check_max_size()\n",
    "            self.__encoding_dataset()\n",
    "            self.message = \"ENCODING OK\"\n",
    "        \n",
    "    def __check_columns_in_df(\n",
    "            self,\n",
    "            check_columns=None,\n",
    "            columns_in_df=None):\n",
    "\n",
    "        response_check = True\n",
    "\n",
    "        for colum in check_columns:\n",
    "            if colum not in columns_in_df:\n",
    "                response_check=False\n",
    "                break\n",
    "        \n",
    "        return response_check\n",
    "    \n",
    "    def __make_validations(self):\n",
    "\n",
    "        # read the dataset with encoders\n",
    "        self.dataset_encoder.index = self.dataset_encoder['residue']\n",
    "        \n",
    "        # check input dataset\n",
    "        if self.name_column_seq in self.dataset.columns:\n",
    "            \n",
    "            if isinstance(self.columns_to_ignore, list):\n",
    "\n",
    "                if len(self.columns_to_ignore)>0:\n",
    "                    \n",
    "                    response_check = self.__check_columns_in_df(\n",
    "                        columns_in_df=self.dataset.columns.values,\n",
    "                        check_columns=self.columns_to_ignore\n",
    "                    )\n",
    "                    if response_check == True:\n",
    "                        self.status=True\n",
    "                    else:\n",
    "                        self.message = \"ERROR: IGNORE COLUMNS NOT IN DATASET COLUMNS\"   \n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                self.message = \"ERROR: THE ATTRIBUTE columns_to_ignore MUST BE A LIST\"\n",
    "        else:\n",
    "            self.message = \"ERROR: COLUMN TO USE AS SEQUENCE IS NOT IN DATASET COLUMNS\"    \n",
    "\n",
    "    def __check_residues(self, residue):\n",
    "        if residue in self.possible_residues:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def __encoding_residue(self, residue):\n",
    "\n",
    "        if self.__check_residues(residue):\n",
    "            return self.dataset_encoder[self.property_encoder][residue]\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def __check_max_size(self):\n",
    "        size_list = [len(seq) for seq in self.dataset[self.name_column_seq]]\n",
    "        return max(size_list)\n",
    "\n",
    "    def __encoding_sequence(self, sequence):\n",
    "\n",
    "        sequence = sequence.upper()\n",
    "        sequence_encoding = []\n",
    "\n",
    "        for i in range(len(sequence)):\n",
    "            residue = sequence[i]\n",
    "            response_encoding = self.__encoding_residue(residue)\n",
    "            if response_encoding != False:\n",
    "                sequence_encoding.append(response_encoding)\n",
    "\n",
    "        # complete zero padding\n",
    "        for k in range(len(sequence_encoding), self.zero_padding):\n",
    "            sequence_encoding.append(0)\n",
    "\n",
    "        return sequence_encoding\n",
    "\n",
    "    def __encoding_dataset(self):\n",
    "\n",
    "        #print(\"Start encoding process\")\n",
    "        if len(self.columns_to_ignore)>0:\n",
    "            df_columns_ignore = self.dataset[self.columns_to_ignore]\n",
    "            dataset_to_encode = self.dataset.drop(columns=self.columns_to_ignore)\n",
    "        else:\n",
    "            df_columns_ignore=None\n",
    "            dataset_to_encode = self.dataset\n",
    "\n",
    "        print(\"Encoding and Processing results\")\n",
    "\n",
    "        matrix_data = []\n",
    "        for index in dataset_to_encode.index:\n",
    "            sequence_encoder = self.__encoding_sequence(sequence=dataset_to_encode[self.name_column_seq][index])\n",
    "            matrix_data.append(sequence_encoder)\n",
    "\n",
    "        print(\"Creating dataset\")\n",
    "        header = ['p_{}'.format(i) for i in range(len(matrix_data[0]))]\n",
    "        print(\"Export dataset\")\n",
    "\n",
    "        self.df_data_encoded = pd.DataFrame(matrix_data, columns=header)\n",
    "\n",
    "        if len(self.columns_to_ignore)>0:\n",
    "            self.df_data_encoded = pd.concat([self.df_data_encoded, df_columns_ignore], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014636aa",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class FFTTransform:\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            dataset=None,\n",
    "            size_data=None,\n",
    "            columns_to_ignore=[]):\n",
    "        \n",
    "        self.size_data = size_data\n",
    "        self.dataset = dataset\n",
    "        self.columns_to_ignore = columns_to_ignore\n",
    "\n",
    "        self.init_process()\n",
    "\n",
    "    def __processing_data_to_fft(self):\n",
    "\n",
    "        print(\"Removing columns data\")\n",
    "        \n",
    "        if len(self.columns_to_ignore) >0:\n",
    "            self.data_ignored = self.dataset[self.columns_to_ignore]\n",
    "            self.dataset = self.dataset.drop(columns=self.columns_to_ignore)\n",
    "    \n",
    "    def __get_near_pow(self):\n",
    "\n",
    "        print(\"Get near pow 2 value\")\n",
    "        list_data = [math.pow(2, i) for i in range(1, 20)]\n",
    "        stop_value = list_data[0]\n",
    "\n",
    "        for value in list_data:\n",
    "            if value >= self.size_data:\n",
    "                stop_value = value\n",
    "                break\n",
    "\n",
    "        self.stop_value = int(stop_value)\n",
    "    \n",
    "    def __complete_zero_padding(self):\n",
    "\n",
    "        print(\"Apply zero padding\")\n",
    "        list_df = [self.dataset]\n",
    "        for i in range(self.size_data, self.stop_value):\n",
    "            column = [0 for k in range(len(self.dataset))]\n",
    "            key_name = \"p_{}\".format(i)\n",
    "            df_tmp = pd.DataFrame()\n",
    "            df_tmp[key_name] = column\n",
    "            list_df.append(df_tmp)\n",
    "\n",
    "        self.dataset = pd.concat(list_df, axis=1)\n",
    "    \n",
    "\n",
    "    def init_process(self):\n",
    "        self.__processing_data_to_fft()\n",
    "        self.__get_near_pow()\n",
    "        self.__complete_zero_padding()\n",
    "\n",
    "    def __create_row(self, index):\n",
    "        row =  self.dataset.iloc[index].tolist()\n",
    "        return row\n",
    "    \n",
    "    def __apply_FFT(self, index):\n",
    "\n",
    "        row = self.__create_row(index)\n",
    "        T = 1.0 / float(self.stop_value)\n",
    "        yf = fft(row)\n",
    "\n",
    "        xf = np.linspace(0.0, 1.0 / (2.0 * T), self.stop_value // 2)\n",
    "        yf = np.abs(yf[0:self.stop_value // 2])\n",
    "        return [value for value in yf]\n",
    "\n",
    "\n",
    "    def encoding_dataset(self):\n",
    "\n",
    "        matrix_response = []\n",
    "        for index in self.dataset.index:\n",
    "            row_fft = self.__apply_FFT(index)\n",
    "            matrix_response.append(row_fft)\n",
    "\n",
    "        print(\"Creating dataset\")\n",
    "        header = ['p_{}'.format(i) for i in range(len(matrix_response[0]))]\n",
    "        print(\"Export dataset\")\n",
    "        df_fft = pd.DataFrame(matrix_response, columns=header)\n",
    "        \n",
    "        if len(self.columns_to_ignore)>0:\n",
    "\n",
    "            df_fft = pd.concat([df_fft, self.data_ignored], axis=1)\n",
    "\n",
    "        return df_fft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670165ea",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cacbc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/human_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e182fdca",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Data Encoding\n",
    "\n",
    "## Physicochemical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ccbfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"length\"] = df[\"sequence\"].apply(lambda x: len(x))\n",
    "df = df[df[\"length\"] <= 50]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7771317",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "aaindex = pd.read_csv(\"aaindex_encoders.csv\")\n",
    "aaindex.index = aaindex[\"residue\"]\n",
    "aaindex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89376f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "physicochemical_instance = PhysicochemicalEncoder(\n",
    "    dataset=df,\n",
    "    sep_dataset=\",\",\n",
    "    property_encoder=\"ANDN920101\",\n",
    "    dataset_encoder=aaindex,\n",
    "    name_column_seq=\"sequence\",\n",
    "    columns_to_ignore=[\"length\", \"response\"]\n",
    ")\n",
    "physicochemical_instance.run_process()\n",
    "physicochemical_instance.df_data_encoded.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc04ebc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## FFT Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8250695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_instance = FFTTransform(\n",
    "    dataset=physicochemical_instance.df_data_encoded,\n",
    "    size_data=len(physicochemical_instance.df_data_encoded.columns)-1,\n",
    "    columns_to_ignore=[\"length\", \"response\"]\n",
    ")\n",
    "df_fft = fft_instance.encoding_dataset()\n",
    "df_fft.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ec9268",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a263b1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fft.drop(columns=[\"length\"], inplace=True)\n",
    "df_fft.to_csv(\"data/human_dataset_fft.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
